{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your directories\n",
    "gt_dir = \"CP/gt/\"\n",
    "pred_dir = \"CP/predict/\"\n",
    "output_fp_dir = 'CP/fp'\n",
    "output_fn_dir = 'CP/fn'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_fp_dir, exist_ok=True)\n",
    "os.makedirs(output_fn_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yolo_file(file_path, include_confidence=False):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    if include_confidence:\n",
    "        objects = [line.strip().split() for line in lines]\n",
    "    else:\n",
    "        objects = [line.strip().split()[:] for line in lines]  # Exclude confidence score for GT\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_fp_fn(gt_objects, pred_objects):\n",
    "    # Placeholder functions for identifying FPs and FNs\n",
    "    # This requires a more complex logic to compare objects\n",
    "    # For simplicity, we'll just return different sets for demonstration\n",
    "    fps = []  # False positives\n",
    "    fns = []  # False negatives\n",
    "\n",
    "    # Example logic to fill fps and fns lists\n",
    "    gt_classes = {obj[0] for obj in gt_objects}\n",
    "    pred_classes = {obj[0] for obj in pred_objects}\n",
    "\n",
    "    # Identify false positives and false negatives\n",
    "    for pred in pred_objects:\n",
    "        if pred[0] not in gt_classes:\n",
    "            fps.append(pred)\n",
    "\n",
    "    for gt in gt_objects:\n",
    "        if gt[0] not in pred_classes:\n",
    "            fns.append(gt)\n",
    "\n",
    "    return fps, fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP and FN separation complete.\n"
     ]
    }
   ],
   "source": [
    "# Loop through the ground truth files\n",
    "for gt_file in os.listdir(gt_dir):\n",
    "    gt_path = os.path.join(gt_dir, gt_file)\n",
    "    pred_path = os.path.join(pred_dir, gt_file)\n",
    "    \n",
    "    # Ensure there's a corresponding prediction file\n",
    "    if os.path.exists(pred_path):\n",
    "        gt_objects = read_yolo_file(gt_path,include_confidence=False)\n",
    "        pred_objects = read_yolo_file(pred_path, include_confidence=True)\n",
    "        \n",
    "        # Identify FP and FN\n",
    "        fps, fns = identify_fp_fn(gt_objects, pred_objects)\n",
    "\n",
    "        # Save FPs and FNs in their respective directories\n",
    "        if fps:  # If there are false positives\n",
    "            with open(os.path.join(output_fp_dir, gt_file), 'w') as fp_file:\n",
    "                for fp in fps:\n",
    "                    fp_file.write(' '.join(fp) + '\\n')\n",
    "\n",
    "        if fns:  # If there are false negatives\n",
    "            with open(os.path.join(output_fn_dir, gt_file), 'w') as fn_file:\n",
    "                for fn in fns:\n",
    "                    fn_file.write(' '.join(fn) + '\\n')\n",
    "\n",
    "print(\"FP and FN separation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP, FN, and TP separation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define your directories\n",
    "gt_dir = \"CP/gt/\"\n",
    "pred_dir = \"CP/predict/\"\n",
    "output_fp_dir = 'CP/fp'\n",
    "output_fn_dir = 'CP/fn'\n",
    "output_tp_dir = 'CP/tp'  \n",
    "os.makedirs(output_fp_dir, exist_ok=True)\n",
    "os.makedirs(output_fn_dir, exist_ok=True)\n",
    "os.makedirs(output_tp_dir, exist_ok=True)\n",
    "\n",
    "def read_yolo_file(file_path, include_confidence=False):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    if include_confidence:\n",
    "        objects = [line.strip().split() for line in lines]\n",
    "    else:\n",
    "        objects = [line.strip().split()[:] for line in lines]  # Exclude confidence score for GT\n",
    "    return objects\n",
    "\n",
    "def identify_fp_fn_tp(gt_objects, pred_objects):\n",
    "    fps = []  # False positives\n",
    "    fns = []  # False negatives\n",
    "    tps = []  # True positives\n",
    "\n",
    "    gt_classes = {obj[0] for obj in gt_objects}\n",
    "    pred_classes = {obj[0] for obj in pred_objects}\n",
    "\n",
    "    for pred in pred_objects:\n",
    "        if pred[0] in gt_classes:\n",
    "            tps.append(pred)\n",
    "        else:\n",
    "            fps.append(pred)\n",
    "\n",
    "    for gt in gt_objects:\n",
    "        if gt[0] not in pred_classes:\n",
    "            fns.append(gt)\n",
    "\n",
    "    return fps, fns, tps\n",
    "\n",
    "# Loop through the ground truth files\n",
    "for gt_file in os.listdir(gt_dir):\n",
    "    gt_path = os.path.join(gt_dir, gt_file)\n",
    "    pred_path = os.path.join(pred_dir, gt_file)\n",
    "    \n",
    "    # Ensure there's a corresponding prediction file\n",
    "    if os.path.exists(pred_path):\n",
    "        gt_objects = read_yolo_file(gt_path,include_confidence=False)\n",
    "        pred_objects = read_yolo_file(pred_path, include_confidence=True)\n",
    "        \n",
    "        # Identify FP, FN, and TP\n",
    "        fps, fns, tps = identify_fp_fn_tp(gt_objects, pred_objects)\n",
    "\n",
    "        # Save FPs, FNs, and TPs in their respective directories\n",
    "        if fps:\n",
    "            with open(os.path.join(output_fp_dir, gt_file), 'w') as fp_file:\n",
    "                for fp in fps:\n",
    "                    fp_file.write(' '.join(fp) + '\\n')\n",
    "\n",
    "        if fns:\n",
    "            with open(os.path.join(output_fn_dir, gt_file), 'w') as fn_file:\n",
    "                for fn in fns:\n",
    "                    fn_file.write(' '.join(fn) + '\\n')\n",
    "\n",
    "        if tps:\n",
    "            with open(os.path.join(output_tp_dir, gt_file), 'w') as tp_file:\n",
    "                for tp in tps:\n",
    "                    tp_file.write(' '.join(tp) + '\\n')\n",
    "\n",
    "print(\"FP, FN, and TP separation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {1: 492, 2: 53, 3: 170, 0: 6911})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_objects_per_class(folder_path):\n",
    "    object_count = defaultdict(int)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    class_id = int(line.split()[0])\n",
    "                    object_count[class_id] += 1\n",
    "\n",
    "    return object_count\n",
    "\n",
    "folder_path = \"CP/tp\"\n",
    "result = count_objects_per_class(folder_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# move files\n",
    "## Schisto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Function to move files with object ID 3 to a separate folder\n",
    "def move_files_with_object_id_3(prediction_folder, output_prediction_folder, ground_truth_folder, output_ground_truth_folder):\n",
    "    # Create output folders if they don't exist\n",
    "    os.makedirs(output_prediction_folder, exist_ok=True)\n",
    "    os.makedirs(output_ground_truth_folder, exist_ok=True)\n",
    "    \n",
    "    # List all files in the prediction folder\n",
    "    prediction_files = os.listdir(prediction_folder)\n",
    "    \n",
    "    for prediction_file in prediction_files:\n",
    "        # Read the prediction file\n",
    "        with open(os.path.join(prediction_folder, prediction_file), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Check if any line contains object ID 3\n",
    "        contains_object_id_3 = any(line.startswith('2 ') for line in lines)\n",
    "        \n",
    "        if contains_object_id_3:\n",
    "            # Move the prediction file to the output prediction folder\n",
    "            shutil.move(os.path.join(prediction_folder, prediction_file), os.path.join(output_prediction_folder, prediction_file))\n",
    "            \n",
    "            # Find and copy the corresponding ground truth file\n",
    "            ground_truth_file = prediction_file  # Assuming ground truth file has the same name\n",
    "            shutil.copy(os.path.join(ground_truth_folder, ground_truth_file), os.path.join(output_ground_truth_folder, ground_truth_file))\n",
    "\n",
    "# Example usage\n",
    "prediction_folder = \"CP/tp\"\n",
    "output_prediction_folder = \"CP/Hookworm_TP\"\n",
    "ground_truth_folder = \"CP/gt/\"\n",
    "output_ground_truth_folder = \"CP/Hookworm_GT\"\n",
    "\n",
    "move_files_with_object_id_3(prediction_folder, output_prediction_folder, ground_truth_folder, output_ground_truth_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Function to move files with object ID 3 to a separate folder\n",
    "def move_files_with_object_id_3(prediction_folder, output_prediction_folder, ground_truth_folder, output_ground_truth_folder):\n",
    "    # Create output folders if they don't exist\n",
    "    os.makedirs(output_prediction_folder, exist_ok=True)\n",
    "    os.makedirs(output_ground_truth_folder, exist_ok=True)\n",
    "    \n",
    "    # List all files in the prediction folder\n",
    "    prediction_files = os.listdir(prediction_folder)\n",
    "    \n",
    "    for prediction_file in prediction_files:\n",
    "        # Read the prediction file\n",
    "        with open(os.path.join(prediction_folder, prediction_file), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Check if any line contains object ID 3\n",
    "        contains_object_id_3 = any(line.startswith('3 ') for line in lines)\n",
    "        \n",
    "        if contains_object_id_3:\n",
    "            # Move the prediction file to the output prediction folder\n",
    "            shutil.move(os.path.join(prediction_folder, prediction_file), os.path.join(output_prediction_folder, prediction_file))\n",
    "            \n",
    "            # Find and copy the corresponding ground truth file\n",
    "            ground_truth_file = prediction_file  # Assuming ground truth file has the same name\n",
    "            shutil.copy(os.path.join(ground_truth_folder, ground_truth_file), os.path.join(output_ground_truth_folder, ground_truth_file))\n",
    "\n",
    "# Example usage\n",
    "prediction_folder = \"CP/tp\"\n",
    "output_prediction_folder = \"CP/Schisto_TP\"\n",
    "ground_truth_folder = \"CP/gt/\"\n",
    "output_ground_truth_folder = \"CP/Schisto_GT\"\n",
    "\n",
    "move_files_with_object_id_3(prediction_folder, output_prediction_folder, ground_truth_folder, output_ground_truth_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Function to move files with object ID 3 to a separate folder\n",
    "def move_files_with_object_id_3(prediction_folder, output_prediction_folder, ground_truth_folder, output_ground_truth_folder):\n",
    "    # Create output folders if they don't exist\n",
    "    os.makedirs(output_prediction_folder, exist_ok=True)\n",
    "    os.makedirs(output_ground_truth_folder, exist_ok=True)\n",
    "    \n",
    "    # List all files in the prediction folder\n",
    "    prediction_files = os.listdir(prediction_folder)\n",
    "    \n",
    "    for prediction_file in prediction_files:\n",
    "        # Read the prediction file\n",
    "        with open(os.path.join(prediction_folder, prediction_file), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Check if any line contains object ID 3\n",
    "        contains_object_id_3 = any(line.startswith('1 ') for line in lines)\n",
    "        \n",
    "        if contains_object_id_3:\n",
    "            # Move the prediction file to the output prediction folder\n",
    "            shutil.move(os.path.join(prediction_folder, prediction_file), os.path.join(output_prediction_folder, prediction_file))\n",
    "            \n",
    "            # Find and copy the corresponding ground truth file\n",
    "            ground_truth_file = prediction_file  # Assuming ground truth file has the same name\n",
    "            shutil.copy(os.path.join(ground_truth_folder, ground_truth_file), os.path.join(output_ground_truth_folder, ground_truth_file))\n",
    "\n",
    "# Example usage\n",
    "prediction_folder = \"CP/tp\"\n",
    "output_prediction_folder = \"CP/Trichuris_TP\"\n",
    "ground_truth_folder = \"CP/gt/\"\n",
    "output_ground_truth_folder = \"CP/Trichuris_GT\"\n",
    "\n",
    "move_files_with_object_id_3(prediction_folder, output_prediction_folder, ground_truth_folder, output_ground_truth_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Function to copy annotation files until the number of object with id 1 reaches 50\n",
    "def copy_files_until_object_id_1_reaches_50(annotation_folder, gt_folder, output_folder, output_gt_folder):\n",
    "    # Create output folders if they don't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(output_gt_folder, exist_ok=True)\n",
    "    \n",
    "    # List all annotation files\n",
    "    annotation_files = os.listdir(annotation_folder)\n",
    "    \n",
    "    count_object_id_1 = 0\n",
    "    for annotation_file in annotation_files:\n",
    "        # Read the annotation file\n",
    "        with open(os.path.join(annotation_folder, annotation_file), 'r') as f:\n",
    "            annotation_lines = f.readlines()\n",
    "        \n",
    "        # Read the corresponding ground truth file\n",
    "        gt_file = annotation_file  # Assuming ground truth file has the same name\n",
    "        with open(os.path.join(gt_folder, gt_file), 'r') as f:\n",
    "            gt_lines = f.readlines()\n",
    "        \n",
    "        # Count the occurrences of object ID 1\n",
    "        count_object_id_1 += sum(1 for line in annotation_lines if line.startswith('3 '))\n",
    "        \n",
    "        # Copy the annotation file to the output folder\n",
    "        shutil.copy(os.path.join(annotation_folder, annotation_file), os.path.join(output_folder, annotation_file))\n",
    "        \n",
    "        # Copy the corresponding ground truth file to the output ground truth folder\n",
    "        shutil.copy(os.path.join(gt_folder, gt_file), os.path.join(output_gt_folder, gt_file))\n",
    "        \n",
    "        # If count_object_id_1 reaches 50, break the loop\n",
    "        if count_object_id_1 >= 73:\n",
    "            break\n",
    "\n",
    "# Example usage\n",
    "annotation_folder = \"CP/Schisto_TP/\"\n",
    "gt_folder = \"CP/Schisto_GT/\"\n",
    "output_folder = \"CP/Schisto_TP_50/\"\n",
    "output_gt_folder = \"CP/Schisto_GT_50/\"\n",
    "\n",
    "copy_files_until_object_id_1_reaches_50(annotation_folder, gt_folder, output_folder, output_gt_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {1: 49, 2: 47, 3: 52, 0: 172})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_objects_per_class(folder_path):\n",
    "    object_count = defaultdict(int)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    class_id = int(line.split()[0])\n",
    "                    object_count[class_id] += 1\n",
    "\n",
    "    return object_count\n",
    "\n",
    "folder_path = \"CP/CP_FINAL_GT_aligned//\"\n",
    "result = count_objects_per_class(folder_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It doesn't work based on on my expectations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function to parse annotations from a YOLO format file\n",
    "def parse_annotations_yolo(annotation_file):\n",
    "    annotations = []\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            obj_id = int(parts[0])\n",
    "            values = list(map(float, parts[1:]))  # Convert all values to float\n",
    "            annotations.append((obj_id, *values))  # Unpack values\n",
    "    return annotations\n",
    "\n",
    "# Function to calculate intersection over union (IoU) between two bounding boxes\n",
    "def calculate_iou(box1, box2):\n",
    "    x_left = max(box1[1] - box1[3] / 2, box2[1] - box2[3] / 2)\n",
    "    y_top = max(box1[2] - box1[4] / 2, box2[2] - box2[4] / 2)\n",
    "    x_right = min(box1[1] + box1[3] / 2, box2[1] + box2[3] / 2)\n",
    "    y_bottom = min(box1[2] + box1[4] / 2, box2[2] + box2[4] / 2)\n",
    "\n",
    "    intersection_area = max(0, x_right - x_left) * max(0, y_bottom - y_top)\n",
    "    box1_area = box1[3] * box1[4]\n",
    "    box2_area = box2[3] * box2[4]\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    iou = intersection_area / union_area if union_area > 0 else 0\n",
    "\n",
    "    return iou\n",
    "\n",
    "# Function to compare and keep aligned objects between GT and prediction annotation files\n",
    "def keep_aligned_objects(gt_folder, pred_folder, output_gt_folder, output_pred_folder, alignment_threshold=0.5):\n",
    "    os.makedirs(output_gt_folder, exist_ok=True)\n",
    "    os.makedirs(output_pred_folder, exist_ok=True)\n",
    "    \n",
    "    gt_files = os.listdir(gt_folder)\n",
    "    pred_files = os.listdir(pred_folder)\n",
    "    \n",
    "    for gt_file in gt_files:\n",
    "        gt_annotations = parse_annotations_yolo(os.path.join(gt_folder, gt_file))\n",
    "        pred_file = gt_file  # Assuming the prediction file has the same name as the GT file\n",
    "        if pred_file in pred_files:\n",
    "            pred_annotations = parse_annotations_yolo(os.path.join(pred_folder, pred_file))\n",
    "            aligned_gt_annotations = []\n",
    "            aligned_pred_annotations = []\n",
    "            for gt_annotation in gt_annotations:\n",
    "                for pred_annotation in pred_annotations:\n",
    "                    iou = calculate_iou(gt_annotation, pred_annotation)\n",
    "                    if iou >= alignment_threshold:\n",
    "                        aligned_gt_annotations.append(gt_annotation)\n",
    "                        aligned_pred_annotations.append(pred_annotation)\n",
    "                        break  # If one aligned object is found, no need to check further\n",
    "            # Write aligned annotations to new GT and prediction files\n",
    "            with open(os.path.join(output_gt_folder, gt_file), 'w') as f:\n",
    "                for annotation in aligned_gt_annotations:\n",
    "                    f.write(' '.join(str(x) for x in annotation) + '\\n')\n",
    "            with open(os.path.join(output_pred_folder, pred_file), 'w') as f:\n",
    "                for annotation in aligned_pred_annotations:\n",
    "                    f.write(' '.join(str(x) for x in annotation) + '\\n')\n",
    "\n",
    "# Example usage\n",
    "gt_folder = \"CP/CP_FINAL_GT/\"\n",
    "pred_folder = \"CP/CP_FINAL_TP/\"\n",
    "output_gt_folder = \"CP/CP_FINAL_GT_aligned/\"\n",
    "output_pred_folder = \"CP/CP_FINAL_TP_aligned/\"\n",
    "\n",
    "keep_aligned_objects(gt_folder, pred_folder, output_gt_folder, output_pred_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def truncate_prediction_files(prediction_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(prediction_folder):\n",
    "        with open(os.path.join(prediction_folder, filename), 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Truncate each line after the 5th value (object height)\n",
    "        truncated_lines = [' '.join(line.split()[:5]) + '\\n' for line in lines]\n",
    "\n",
    "        # Write truncated lines to new file\n",
    "        with open(os.path.join(output_folder, filename), 'w') as file:\n",
    "            file.writelines(truncated_lines)\n",
    "\n",
    "# Example usage\n",
    "prediction_folder = \"CP/CP_FINAL_TP/\"\n",
    "output_folder = \"CP/CP_FINAL_TP_truncated/\"\n",
    "\n",
    "truncate_prediction_files(prediction_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_images_based_on_annotations(image_folder, annotation_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get list of annotation filenames without extensions\n",
    "    annotation_filenames = [os.path.splitext(filename)[0] for filename in os.listdir(annotation_folder)]\n",
    "\n",
    "    # Iterate through images and copy them if their corresponding annotation exists\n",
    "    for filename in os.listdir(image_folder):\n",
    "        image_name_without_extension = os.path.splitext(filename)[0]\n",
    "        if image_name_without_extension in annotation_filenames:\n",
    "            shutil.copy(os.path.join(image_folder, filename), os.path.join(output_folder, filename))\n",
    "\n",
    "# Example usage\n",
    "image_folder = \"CP/images/\"\n",
    "annotation_folder = \"CP/CP_FINAL_GT/\"\n",
    "output_folder = \"CP/images_with_annotations_aligned/\"\n",
    "\n",
    "copy_images_based_on_annotations(image_folder, annotation_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to extract annotations from annotation files and store them in a CSV file\n",
    "def create_annotation_csv(annotation_folder, output_csv_file):\n",
    "    # List all annotation files\n",
    "    annotation_files = os.listdir(annotation_folder)\n",
    "    \n",
    "    with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write header\n",
    "        csv_writer.writerow(['File Name', 'Object ID', 'X Center', 'Y Center', 'Width', 'Height'])\n",
    "        \n",
    "        # Process each annotation file\n",
    "        for annotation_file in annotation_files:\n",
    "            # Read the annotation file\n",
    "            with open(os.path.join(annotation_folder, annotation_file), 'r') as f:\n",
    "                annotation_lines = f.readlines()\n",
    "            \n",
    "            # Extract annotations for each object\n",
    "            for line in annotation_lines:\n",
    "                parts = line.strip().split()\n",
    "                obj_id = parts[0]\n",
    "                x_center = parts[1]\n",
    "                y_center = parts[2]\n",
    "                obj_width = parts[3]\n",
    "                obj_height = parts[4]\n",
    "                # conf_score = parts[5]\n",
    "                \n",
    "                # Write object details to CSV file\n",
    "                csv_writer.writerow([annotation_file, obj_id, x_center, y_center, obj_width, obj_height])\n",
    "\n",
    "# Example usage\n",
    "annotation_folder = \"CP/CP_FINAL_GT/\"\n",
    "output_csv_file = \"CP/GT.csv\"\n",
    "\n",
    "create_annotation_csv(annotation_folder, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to extract annotations from annotation files and store them in a CSV file\n",
    "def create_annotation_csv(annotation_folder, output_csv_file):\n",
    "    # List all annotation files\n",
    "    annotation_files = os.listdir(annotation_folder)\n",
    "    \n",
    "    with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write header\n",
    "        csv_writer.writerow(['File Name', 'Object ID', 'X Center', 'Y Center', 'Width', 'Height'])\n",
    "        \n",
    "        # Process each annotation file\n",
    "        for annotation_file in annotation_files:\n",
    "            # Read the annotation file\n",
    "            with open(os.path.join(annotation_folder, annotation_file), 'r') as f:\n",
    "                annotation_lines = f.readlines()\n",
    "            \n",
    "            # Extract annotations for each object\n",
    "            for line in annotation_lines:\n",
    "                parts = line.strip().split()\n",
    "                obj_id = parts[0]\n",
    "                x_center = parts[1]\n",
    "                y_center = parts[2]\n",
    "                obj_width = parts[3]\n",
    "                obj_height = parts[4]\n",
    "                # conf_score = parts[5]\n",
    "                \n",
    "                # Write object details to CSV file\n",
    "                csv_writer.writerow([annotation_file, obj_id, x_center, y_center, obj_width, obj_height])\n",
    "\n",
    "# Example usage\n",
    "annotation_folder = \"CP/CP_FINAL_GT/\"\n",
    "output_csv_file = \"CP/GT.csv\"\n",
    "\n",
    "create_annotation_csv(annotation_folder, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to extract annotations from annotation files and store them in a CSV file\n",
    "def create_annotation_csv(annotation_folder, output_csv_file):\n",
    "    # List all annotation files\n",
    "    annotation_files = os.listdir(annotation_folder)\n",
    "    \n",
    "    with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write header\n",
    "        csv_writer.writerow(['File Name', 'Object ID', 'X Center', 'Y Center', 'Width', 'Height', 'Confidence Score', 'Object Score', 'Ascaris Confidence Score', 'Trichuris Confidence Score', 'Hookworm Confidence Score', 'Schistosoma Confidence Score'])\n",
    "        \n",
    "        # Process each annotation file\n",
    "        for annotation_file in annotation_files:\n",
    "            # Read the annotation file\n",
    "            with open(os.path.join(annotation_folder, annotation_file), 'r') as f:\n",
    "                annotation_lines = f.readlines()\n",
    "            \n",
    "            # Extract annotations for each object\n",
    "            for line in annotation_lines:\n",
    "                parts = line.strip().split()\n",
    "                obj_id = parts[0]\n",
    "                x_center = parts[1]\n",
    "                y_center = parts[2]\n",
    "                obj_width = parts[3]\n",
    "                obj_height = parts[4]\n",
    "                conf_score = parts[5]\n",
    "                obj_score = parts[6]\n",
    "                ascaris_conf_score = parts[7]\n",
    "                trichuris_conf_score = parts[8]\n",
    "                hookworm_conf_score = parts[9]\n",
    "                schistosoma_conf_score = parts[10]\n",
    "                \n",
    "                # Write object details to CSV file\n",
    "                csv_writer.writerow([annotation_file, obj_id, x_center, y_center, obj_width, obj_height, conf_score, obj_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score])\n",
    "\n",
    "# Example usage\n",
    "annotation_folder = \"CP/CP_FINAL_TP/\"\n",
    "output_csv_file = \"CP/TP.csv\"\n",
    "\n",
    "create_annotation_csv(annotation_folder, output_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define your directories\n",
    "gt_dir = \"CP/CP_FINAL_GT - Copy/\"\n",
    "pred_dir = \"CP/CP_FINAL_TP - Copy/\"\n",
    "output_tp_dir = \"CP/CP_FINAL_TP_only\"\n",
    "os.makedirs(output_tp_dir, exist_ok=True)\n",
    "\n",
    "def read_yolo_file(file_path, include_confidence=False):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    if include_confidence:\n",
    "        objects = [line.strip().split() for line in lines]\n",
    "    else:\n",
    "        objects = [line.strip().split()[:] for line in lines]  # Exclude confidence score for GT\n",
    "    return objects\n",
    "\n",
    "def identify_tp(gt_objects, pred_objects):\n",
    "    tps = []  # True positives\n",
    "\n",
    "    gt_classes = {obj[0] for obj in gt_objects}\n",
    "    pred_classes = {obj[0] for obj in pred_objects}\n",
    "\n",
    "    for pred in pred_objects:\n",
    "        if pred[0] in gt_classes:\n",
    "            tps.append(pred)\n",
    "\n",
    "    return tps\n",
    "\n",
    "# Loop through the ground truth files\n",
    "for gt_file in os.listdir(gt_dir):\n",
    "    gt_path = os.path.join(gt_dir, gt_file)\n",
    "    pred_path = os.path.join(pred_dir, gt_file)\n",
    "    \n",
    "    # Ensure there's a corresponding prediction file\n",
    "    if os.path.exists(pred_path):\n",
    "        gt_objects = read_yolo_file(gt_path,include_confidence=False)\n",
    "        pred_objects = read_yolo_file(pred_path, include_confidence=True)\n",
    "        \n",
    "        # Identify TP\n",
    "        tps = identify_tp(gt_objects, pred_objects)\n",
    "\n",
    "        # Save TPs in their respective directories\n",
    "        if tps:\n",
    "            with open(os.path.join(output_tp_dir, gt_file), 'w') as tp_file:\n",
    "                for tp in tps:\n",
    "                    tp_file.write(' '.join(tp) + '\\n')\n",
    "\n",
    "print(\"TP extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from PIL import Image\n",
    "\n",
    "# Function to calculate IoU\n",
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    # Calculate coordinates of intersection rectangle\n",
    "    x_left = max(x1 - w1 / 2, x2 - w2 / 2)\n",
    "    y_top = max(y1 - h1 / 2, y2 - h2 / 2)\n",
    "    x_right = min(x1 + w1 / 2, x2 + w2 / 2)\n",
    "    y_bottom = min(y1 + h1 / 2, y2 + h2 / 2)\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # Calculate area of each bounding box\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / (box1_area + box2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "# Folder paths\n",
    "images_folder = \"CP/images_with_annotations_aligned/\"\n",
    "gt_folder = \"CP/CP_FINAL_GT_aligned/\"\n",
    "prediction_folder = \"CP/CP_FINAL_TP_aligned/\"\n",
    "\n",
    "# Output CSV file\n",
    "output_csv = \"CP/output.csv\"\n",
    "\n",
    "# Dictionary to store annotations\n",
    "annotations = defaultdict(list)\n",
    "\n",
    "# Iterate through images folder\n",
    "for filename in os.listdir(images_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Get image dimensions\n",
    "        img = Image.open(os.path.join(images_folder, filename))\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Get corresponding ground truth and prediction files\n",
    "        gt_file = os.path.join(gt_folder, filename.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "        pred_file = os.path.join(prediction_folder, filename.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "\n",
    "        # Read GT annotations\n",
    "        with open(gt_file, \"r\") as f:\n",
    "            gt_annotations = [list(map(float, line.strip().split())) for line in f]\n",
    "\n",
    "        # Read prediction annotations\n",
    "        with open(pred_file, \"r\") as f:\n",
    "            pred_annotations = [list(map(float, line.strip().split())) for line in f]\n",
    "\n",
    "        # Align GT and prediction annotations based on IoU\n",
    "        for gt_obj in gt_annotations:\n",
    "            gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height = gt_obj\n",
    "            matched_pred = None\n",
    "            max_iou = 0\n",
    "\n",
    "            for pred_obj in pred_annotations:\n",
    "                iou = calculate_iou((gt_x_center, gt_y_center, gt_obj_width, gt_obj_height), pred_obj[1:5])\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    matched_pred = pred_obj\n",
    "\n",
    "            if max_iou >= 0.5:\n",
    "                pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score = matched_pred\n",
    "                annotations[filename].append((filename, img_width, img_height, gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height, pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score))\n",
    "\n",
    "# Write annotations to CSV\n",
    "with open(output_csv, \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"filename\", \"image_width\", \"image_height\", \"gt_obj_id\", \"gt_x_center\", \"gt_y_center\", \"gt_obj_width\", \"gt_obj_height\", \"pred_obj_id\", \"pred_x_center\", \"pred_y_center\", \"pred_obj_width\", \"pred_obj_height\", \"conf_score\", \"objectness_score\", \"ascaris_conf_score\", \"trichuris_conf_score\", \"hookworm_conf_score\", \"schistosoma_conf_score\"])\n",
    "    for filename, ann_list in annotations.items():\n",
    "        for ann in ann_list:\n",
    "            csv_writer.writerow(ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from PIL import Image\n",
    "\n",
    "# Function to calculate IoU\n",
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    # Calculate coordinates of intersection rectangle\n",
    "    x_left = max(x1 - w1 / 2, x2 - w2 / 2)\n",
    "    y_top = max(y1 - h1 / 2, y2 - h2 / 2)\n",
    "    x_right = min(x1 + w1 / 2, x2 + w2 / 2)\n",
    "    y_bottom = min(y1 + h1 / 2, y2 + h2 / 2)\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # Calculate area of each bounding box\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / (box1_area + box2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "# Folder paths\n",
    "images_folder = \"CP/GrTru/images/\"\n",
    "gt_folder = \"CP/GrTru/labels/\"\n",
    "prediction_folder = \"runs/detect/conformal_prediction_25/labels/\"\n",
    "\n",
    "# Output CSV file\n",
    "output_csv = \"CP/conf_25.csv\"\n",
    "\n",
    "# Dictionary to store annotations\n",
    "annotations = defaultdict(list)\n",
    "\n",
    "# Set to keep track of matched predictions\n",
    "matched_predictions = set()\n",
    "\n",
    "# Iterate through images folder\n",
    "for filename in os.listdir(images_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Get image dimensions\n",
    "        img = Image.open(os.path.join(images_folder, filename))\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Get corresponding ground truth and prediction files\n",
    "        gt_file = os.path.join(gt_folder, filename.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "        pred_file = os.path.join(prediction_folder, filename.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "\n",
    "        # Read GT annotations\n",
    "        with open(gt_file, \"r\") as f:\n",
    "            gt_annotations = [list(map(float, line.strip().split())) for line in f]\n",
    "\n",
    "        # Read prediction annotations\n",
    "        with open(pred_file, \"r\") as f:\n",
    "            pred_annotations = [list(map(float, line.strip().split())) for line in f]\n",
    "\n",
    "        # Align GT and prediction annotations based on IoU\n",
    "        for gt_obj in gt_annotations:\n",
    "            gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height = gt_obj\n",
    "            matched_pred = None\n",
    "            max_iou = 0\n",
    "\n",
    "            for pred_obj in pred_annotations:\n",
    "                iou = calculate_iou((gt_x_center, gt_y_center, gt_obj_width, gt_obj_height), pred_obj[1:5])\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    matched_pred = pred_obj\n",
    "\n",
    "            if max_iou >= 0.5:\n",
    "                pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score = matched_pred\n",
    "                annotations[filename].append((filename, img_width, img_height, gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height, pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score))\n",
    "                matched_predictions.add(tuple(matched_pred))\n",
    "            else:\n",
    "                # If IoU is less than 0.5, it's a false negative\n",
    "                annotations[filename].append((filename, img_width, img_height, gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"))\n",
    "        \n",
    "        # Look for false positive predictions\n",
    "        for pred_obj in pred_annotations:\n",
    "            if tuple(pred_obj) not in matched_predictions:\n",
    "                pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score = pred_obj\n",
    "                annotations[filename].append((filename, img_width, img_height, \"\", \"\", \"\", \"\", \"\", pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score))\n",
    "\n",
    "# Write annotations to CSV\n",
    "with open(output_csv, \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"filename\", \"image_width\", \"image_height\", \"gt_obj_id\", \"gt_x_center\", \"gt_y_center\", \"gt_obj_width\", \"gt_obj_height\", \"pred_obj_id\", \"pred_x_center\", \"pred_y_center\", \"pred_obj_width\", \"pred_obj_height\", \"conf_score\", \"objectness_score\", \"ascaris_conf_score\", \"trichuris_conf_score\", \"hookworm_conf_score\", \"schistosoma_conf_score\"])\n",
    "    for filename, ann_list in annotations.items():\n",
    "        for ann in ann_list:\n",
    "            csv_writer.writerow(ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from PIL import Image\n",
    "\n",
    "# Function to calculate IoU\n",
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    # Calculate coordinates of intersection rectangle\n",
    "    x_left = max(x1 - w1 / 2, x2 - w2 / 2)\n",
    "    y_top = max(y1 - h1 / 2, y2 - h2 / 2)\n",
    "    x_right = min(x1 + w1 / 2, x2 + w2 / 2)\n",
    "    y_bottom = min(y1 + h1 / 2, y2 + h2 / 2)\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # Calculate area of each bounding box\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / (box1_area + box2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "# Folder paths\n",
    "images_folder = \"CP/GrTru/images/\"\n",
    "gt_folder = \"CP/GrTru/labels/\"\n",
    "prediction_folder = \"runs/detect/conformal_prediction_25/labels/\"\n",
    "\n",
    "# Output CSV file\n",
    "output_csv = \"CP/25.csv\"\n",
    "\n",
    "# Dictionary to store annotations\n",
    "annotations = defaultdict(list)\n",
    "\n",
    "# Set to keep track of matched predictions\n",
    "matched_predictions = set()\n",
    "\n",
    "# Iterate through images folder\n",
    "for filename in os.listdir(images_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Get image dimensions\n",
    "        img = Image.open(os.path.join(images_folder, filename))\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Get corresponding ground truth and prediction files\n",
    "        gt_file = os.path.join(gt_folder, filename.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "        pred_file = os.path.join(prediction_folder, filename.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "\n",
    "        # Read GT annotations\n",
    "        with open(gt_file, \"r\") as f:\n",
    "            gt_annotations = [list(map(float, line.strip().split())) for line in f]\n",
    "\n",
    "        # Read prediction annotations\n",
    "        with open(pred_file, \"r\") as f:\n",
    "            pred_annotations = [list(map(float, line.strip().split())) for line in f]\n",
    "\n",
    "        # Align GT and prediction annotations based on IoU\n",
    "        for gt_obj in gt_annotations:\n",
    "            gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height = gt_obj\n",
    "            matched_pred = None\n",
    "            max_iou = 0\n",
    "\n",
    "            for pred_obj in pred_annotations:\n",
    "                iou = calculate_iou((gt_x_center, gt_y_center, gt_obj_width, gt_obj_height), pred_obj[1:5])\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    matched_pred = pred_obj\n",
    "\n",
    "            if max_iou >= 0.5:\n",
    "                pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score = matched_pred\n",
    "                annotations[filename].append((filename, img_width, img_height, gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height, pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score))\n",
    "                matched_predictions.add(tuple(matched_pred))\n",
    "            else:\n",
    "                # If IoU is less than 0.5, it's a false negative\n",
    "                annotations[filename].append((filename, img_width, img_height, gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height, \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"\"))\n",
    "        \n",
    "        # Look for false positive predictions\n",
    "        for pred_obj in pred_annotations:\n",
    "            if tuple(pred_obj) not in matched_predictions:\n",
    "                pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score = pred_obj\n",
    "                annotations[filename].append((filename, img_width, img_height, \"-\", \"-\", \"-\", \"-\", \"-\", pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score))\n",
    "\n",
    "# Write annotations to CSV\n",
    "with open(output_csv, \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"filename\", \"image_width\", \"image_height\", \"gt_obj_id\", \"gt_x_center\", \"gt_y_center\", \"gt_obj_width\", \"gt_obj_height\", \"pred_obj_id\", \"pred_x_center\", \"pred_y_center\", \"pred_obj_width\", \"pred_obj_height\", \"conf_score\", \"objectness_score\", \"ascaris_conf_score\", \"trichuris_conf_score\", \"hookworm_conf_score\", \"schistosoma_conf_score\"])\n",
    "    for filename, ann_list in annotations.items():\n",
    "        for ann in ann_list:\n",
    "            csv_writer.writerow(ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CP/old_dataset/test_old_u/test_0.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m     gt_annotations \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit())) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Read prediction annotations\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpred_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     63\u001b[0m     pred_annotations \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit())) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Align GT and prediction annotations based on IoU\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\M\\Documents\\LifeLongLearning\\Courses\\LLMs\\llms_cuda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CP/old_dataset/test_old_u/test_0.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from PIL import Image\n",
    "\n",
    "# Function to calculate IoU\n",
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    # Calculate coordinates of intersection rectangle\n",
    "    x_left = max(x1 - w1 / 2, x2 - w2 / 2)\n",
    "    y_top = max(y1 - h1 / 2, y2 - h2 / 2)\n",
    "    x_right = min(x1 + w1 / 2, x2 + w2 / 2)\n",
    "    y_bottom = min(y1 + h1 / 2, y2 + h2 / 2)\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # Calculate area of each bounding box\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / (box1_area + box2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "# Folder paths\n",
    "images_folder = \"CP/GrTru/test/images/\"\n",
    "gt_folder = \"CP/GrTru/test/labels/\"\n",
    "prediction_folder = \"runs/detect/test_25/labels/\"\n",
    "\n",
    "# Output CSV file\n",
    "output_csv = \"CP/test_conf_score_25.csv\"\n",
    "\n",
    "# Dictionary to store annotations\n",
    "annotations = defaultdict(list)\n",
    "\n",
    "# Set to keep track of matched predictions\n",
    "matched_predictions = set()\n",
    "\n",
    "# Iterate through images folder\n",
    "for filename in os.listdir(images_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Get image dimensions\n",
    "        img = Image.open(os.path.join(images_folder, filename))\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Get corresponding ground truth and prediction files\n",
    "        gt_file = os.path.join(gt_folder, filename.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "        pred_file = os.path.join(prediction_folder, filename.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "\n",
    "        # Read GT annotations\n",
    "        with open(gt_file, \"r\") as f:\n",
    "            gt_annotations = [list(map(float, line.strip().split())) for line in f]\n",
    "\n",
    "        # Read prediction annotations\n",
    "        with open(pred_file, \"r\") as f:\n",
    "            pred_annotations = [list(map(float, line.strip().split())) for line in f]\n",
    "\n",
    "        # Align GT and prediction annotations based on IoU\n",
    "        for gt_obj in gt_annotations:\n",
    "            gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height = gt_obj\n",
    "            matched_pred = None\n",
    "            max_iou = 0\n",
    "\n",
    "            for pred_obj in pred_annotations:\n",
    "                iou = calculate_iou((gt_x_center, gt_y_center, gt_obj_width, gt_obj_height), pred_obj[1:5])\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    matched_pred = pred_obj\n",
    "\n",
    "            if max_iou >= 0.5:\n",
    "                pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score = matched_pred\n",
    "                annotations[filename].append((filename, img_width, img_height, gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height, pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score))\n",
    "                matched_predictions.add(tuple(matched_pred))\n",
    "            else:\n",
    "                # If IoU is less than 0.5, it's a false negative\n",
    "                annotations[filename].append((filename, img_width, img_height, gt_obj_id, gt_x_center, gt_y_center, gt_obj_width, gt_obj_height, \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"\"))\n",
    "        \n",
    "        # Look for false positive predictions\n",
    "        for pred_obj in pred_annotations:\n",
    "            if tuple(pred_obj) not in matched_predictions:\n",
    "                pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score = pred_obj\n",
    "                annotations[filename].append((filename, img_width, img_height, \"-\", \"-\", \"-\", \"-\", \"-\", pred_obj_id, pred_x_center, pred_y_center, pred_obj_width, pred_obj_height, conf_score, objectness_score, ascaris_conf_score, trichuris_conf_score, hookworm_conf_score, schistosoma_conf_score))\n",
    "\n",
    "# Write annotations to CSV\n",
    "with open(output_csv, \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"filename\", \"image_width\", \"image_height\", \"gt_obj_id\", \"gt_x_center\", \"gt_y_center\", \"gt_obj_width\", \"gt_obj_height\", \"pred_obj_id\", \"pred_x_center\", \"pred_y_center\", \"pred_obj_width\", \"pred_obj_height\", \"conf_score\", \"objectness_score\", \"ascaris_conf_score\", \"trichuris_conf_score\", \"hookworm_conf_score\", \"schistosoma_conf_score\"])\n",
    "    for filename, ann_list in annotations.items():\n",
    "        for ann in ann_list:\n",
    "            csv_writer.writerow(ann)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
